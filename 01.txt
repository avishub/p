1. Installing Java
	sudo apt-get update
	sudo apt-get install openjdk-8-jdk
	javac -version
	
	update-alternatives --config java 
	gedit /etc/environment
	JAVA_HOME="/usr/lib/jvm/java-8-openjdk-i386"
	source /etc/environment
	echo $JAVA_HOME
	
2. Installing ssh
	sudo apt-get install ssh
	ssh-keygen -t rse -P ""
	cat $HOME/.ssh/id_rsa.pub >> $HOME/.ssh/authorized_keys
	ssh localhost
	
3. Installing Hadoop
	Download and extract
	tar -xvzf <name>
	
	sudo gedit .bashrc
-----------------------------------------------
Append following lines to the end of  ~/.bashrc:

#HADOOP VARIABLES START
export JAVA_HOME=/usr/lib/jvm
export HADOOP_INSTALL=/usr/local
export PATH=$PATH:$HADOOP_INSTALL/bin
export PATH=$PATH:$HADOOP_INSTALL/sbin
export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_HOME=$HADOOP_INSTALL
export HADOOP_HDFS_HOME=$HADOOP_INSTALL
export YARN_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_INSTALL/lib"
#HADOOP VARIABLES END
-----------------------------------------------
	 source .bashrc
	 
	 cd hadoop/etc/hadoop/
	 sudo gedit hadoop-env.sh
_______________________________________________

Append the following line to hadoop-env.sh:
export JAVA_HOME=/usr/lib/jvm
_______________________________________________	 
	 
	 mkdir /usr/local/hadoop_store/hdfs/namenode
	 mkdir /usr/local/hadoop_store/hdfs/datanode
	 
	 sudo gedit hdfs-site.xml
	 
------------------------------------------------

	for hdfs-site.xml:

 <property>
  <name>dfs.replication</name>
  <value>1</value>
  <description>Default block replication.
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time.
  </description>
 </property>
 <property>
   <name>dfs.namenode.name.dir</name>
  <value>file:######NAMENODE_FOLDER_PATH######</value>
 </property>
 <property>
   <name>dfs.datanode.data.dir</name>
   <value>file:######DATANODE_FOLDER_PATH######</value>
 </property>
------------------------------------------------	 
	
	 mkdir hadoop/tmp	 
	 sudo gedit core-site.xml
	 
-------------------------
for core-site.xml:
 <property>
  <name>hadoop.tmp.dir</name>
  <value>/home/</value>
  <description>A base for other temporary directories.</description>
 </property>
 <property>
  <name>fs.default.name</name>
  <value>hdfs://localhost:54310</value>
  <description>The name of the default file system.  A URI whose
  scheme and authority determine the FileSystem implementation.  The
  uri's scheme determines the config property (fs.SCHEME.impl) naming
  the FileSystem implementation class.  The uri's authority is used to
  determine the host, port, etc. for a filesystem.</description>
 </property>

----------------------------
	
	cp mapred-site-.xml.template mapred-site.xml
	sudo gedit mared-site.xml
	
---------------------------------

for mapred-site.xml:
 <property>
  <name>mapred.job.tracker</name>
  <value>localhost:54311</value>
  <description>The host and port that the MapReduce job tracker runs
  at.  If "local", then jobs are run in-process as a single map
  and reduce task.
  </description>
 </property>
-----------------------------------
	 
	hadoop namenode -format
	
	jps
	
	start-all.sh
	
	jps
	
	
===========================================================================	



	
	 
	 	 
	 
	 

	
	
	
	
	
		
	
	
	
	
